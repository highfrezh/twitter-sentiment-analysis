{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MWfE0sgZedB"
   },
   "source": [
    "importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "M2qtiquzYq3C"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Opx3tXgZkZ0",
    "outputId": "89134a52-dfc7-4e37-b705-fbaced39fd24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/highfrezh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1f-wYCXZ8Xg",
    "outputId": "872196d8-13df-4e85-e9ed-2cb2ab5efabf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# printing the stopwords in english\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqyFbqX-aWxt"
   },
   "source": [
    "Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "L0nrO02saIOG"
   },
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "df = pd.read_csv('archive/training.1600000.processed.noemoticon.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJL0fn2CbOY8",
    "outputId": "364e8916-650c-446f-96b2-41c4c8ef31a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599999, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the number of rows and column\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "gu5DxUSRbY2_",
    "outputId": "0ed2111b-c641-483b-bd58-fe015712c3c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 1599999\n",
      "Sampled dataset size: 160000\n"
     ]
    }
   ],
   "source": [
    "sampled_df = df.sample(frac=0.1, random_state=42)  # Randomly select 10% of rows\n",
    "\n",
    "print(f\"Original dataset size: {len(df)}\")\n",
    "print(f\"Sampled dataset size: {len(sampled_df)}\")\n",
    "\n",
    "# If you want to reset the index after sampling:\n",
    "sampled_df = sampled_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "bXlPtisabmhh",
    "outputId": "ebb52b79-6512-454a-fc96-6b4c8f922b6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2200003313</td>\n",
       "      <td>Tue Jun 16 18:18:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>DEWGetMeTho77</td>\n",
       "      <td>@Nkluvr4eva My poor little dumpling  In Holmde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467998601</td>\n",
       "      <td>Mon Apr 06 23:11:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Young_J</td>\n",
       "      <td>I'm off too bed. I gotta wake up hella early t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2300049112</td>\n",
       "      <td>Tue Jun 23 13:40:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>dougnawoschik</td>\n",
       "      <td>I havent been able to listen to it yet  My spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1993474319</td>\n",
       "      <td>Mon Jun 01 10:26:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>thireven</td>\n",
       "      <td>now remembers why solving a relatively big equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2256551006</td>\n",
       "      <td>Sat Jun 20 12:56:51 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>taracollins086</td>\n",
       "      <td>Ate too much, feel sick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag            user  \\\n",
       "0       0  2200003313  Tue Jun 16 18:18:13 PDT 2009  NO_QUERY   DEWGetMeTho77   \n",
       "1       0  1467998601  Mon Apr 06 23:11:18 PDT 2009  NO_QUERY         Young_J   \n",
       "2       0  2300049112  Tue Jun 23 13:40:12 PDT 2009  NO_QUERY   dougnawoschik   \n",
       "3       0  1993474319  Mon Jun 01 10:26:09 PDT 2009  NO_QUERY        thireven   \n",
       "4       0  2256551006  Sat Jun 20 12:56:51 PDT 2009  NO_QUERY  taracollins086   \n",
       "\n",
       "                                                text  \n",
       "0  @Nkluvr4eva My poor little dumpling  In Holmde...  \n",
       "1  I'm off too bed. I gotta wake up hella early t...  \n",
       "2  I havent been able to listen to it yet  My spe...  \n",
       "3  now remembers why solving a relatively big equ...  \n",
       "4                           Ate too much, feel sick   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renaming the columns and reading the dataset again\n",
    "sampled_df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "U635BuIedCSf",
    "outputId": "33943222-9cf8-467b-b51d-b12032dc589f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "ids       0\n",
       "date      0\n",
       "flag      0\n",
       "user      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting the number of missing values in the dataset\n",
    "sampled_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "tS48M0mWdVG1",
    "outputId": "89bdc410-9199-46a8-db7b-2db7dddadc7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "4    80188\n",
       "0    79812\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of target column\n",
    "sampled_df['target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cohVfRc-d7nX"
   },
   "source": [
    "Convert the target \"4\" to \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WTYlkDKHd3jv"
   },
   "outputs": [],
   "source": [
    "sampled_df['target'] = sampled_df['target'].replace(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "HnnazMU6eiMD",
    "outputId": "d5fe42d7-ed08-49c0-bc0b-acb4931ac3fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    80188\n",
       "0    79812\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of target column\n",
    "sampled_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCsSrOgOeq62"
   },
   "source": [
    "\"0\" means negative\n",
    "\"1\" means positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmGdH4Mse6zn"
   },
   "source": [
    "Stemming <br>\n",
    "\n",
    "Stemming is the process of reducing a word to it root word\n",
    "\n",
    "example: actor. actress, acting = act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "d1KJu3EVewO8"
   },
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "KThxrArSfh9F"
   },
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]', ' ', content)\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LnFzJ6m2hp3f"
   },
   "outputs": [],
   "source": [
    "sampled_df['stemmed_content'] = sampled_df['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1ayctWGiOcF"
   },
   "outputs": [],
   "source": [
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcny3zBjicZo"
   },
   "outputs": [],
   "source": [
    "print(sampled_df['stemmed_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqhp3XBFjMWX"
   },
   "outputs": [],
   "source": [
    "print(sampled_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkI-5Qq8jSyu"
   },
   "outputs": [],
   "source": [
    "# Seperating the data and lebel\n",
    "X = sampled_df['stemmed_content'].values\n",
    "Y = sampled_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zuyMO7wkAlL"
   },
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHDN0amDkHT7"
   },
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pe-YAKfkRWX"
   },
   "source": [
    "Spliting the data to training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lx53WAfOkKst"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZl_r5SblVED"
   },
   "outputs": [],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNV2GSfSlZm6"
   },
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voqR4YEMlf19"
   },
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xx-mnZvYlp9x"
   },
   "outputs": [],
   "source": [
    "# converting the textual data to numerical data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train) # two process happening here\n",
    "X_test = vectorizer.transform(X_test) # one process happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8SQNbj1nYgD"
   },
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2L4fMAyFn4_X"
   },
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWFEZFxjoRND"
   },
   "source": [
    "Training the machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBotnxm5oZSf"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKGqpM9eoFej"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_t-gDkAbolGn"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gg66trmVpNw5"
   },
   "source": [
    "Model Evaluation\n",
    "\n",
    "\n",
    "Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4VVA45hTpY92"
   },
   "outputs": [],
   "source": [
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jlvnl5ddpuEs"
   },
   "outputs": [],
   "source": [
    "print('Accuracy score of the training data : ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LvLyh80qGyN"
   },
   "outputs": [],
   "source": [
    "#accuracy score on test data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEMDH8OyqgBC"
   },
   "outputs": [],
   "source": [
    "print('Accuracy score of the test data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfmGweeVrL7f"
   },
   "source": [
    "Model Accuracy = 77.8%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dT3f9nk2reyU"
   },
   "source": [
    "Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNtTnuL_rdJt"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMJU4iSDrppf"
   },
   "outputs": [],
   "source": [
    "filename = 'trained_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "571kzQIbsGfH"
   },
   "source": [
    "Using the saved model for future prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGRq5x1XsMpZ"
   },
   "outputs": [],
   "source": [
    "# loading the saved model\n",
    "loaded_model = pickle.load(open('trained_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "napy6LOUsbfl"
   },
   "outputs": [],
   "source": [
    "X_new = X_test[200]\n",
    "print(Y_test[200])\n",
    "\n",
    "prediction = loaded_model.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]==0):\n",
    "  print('The news is Negative')\n",
    "else:\n",
    "  print('The news is Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDKmdmastLkH"
   },
   "outputs": [],
   "source": [
    "X_new = X_test[3]\n",
    "print(Y_test[3])\n",
    "\n",
    "prediction = loaded_model.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]==0):\n",
    "  print('The news is Negative')\n",
    "else:\n",
    "  print('The news is Positive')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
